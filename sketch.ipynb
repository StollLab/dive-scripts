{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('dive2': conda)",
   "metadata": {
    "interpreter": {
     "hash": "b6d418bc6bf2c838c9ea653afd9d1ef4df19f5263e479410634954ce1dff87eb"
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### These are some links that might help with writing the custom sampler:\n",
    "- https://learning.oreilly.com/library/view/bayesian-data-analysis/9781439898222/OEBPS/pI.htm\n",
    "- https://docs.pymc.io/notebooks/getting_started.html\n",
    "- https://nbviewer.jupyter.org/gist/aflaxman/91d462301855d6942506\n",
    "- https://docs.pymc.io/notebooks/sampling_compound_step.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pymc3 as pm\n",
    "import math as m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dipolarkernel import kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data loading\n",
    "FileName = \"3992_good_results.dat\"\n",
    "\n",
    "ImportedData = np.genfromtxt(\"./data/%s\" % FileName, delimiter=',',skip_header=1)\n",
    "t = ImportedData[:,0]\n",
    "Vdata = ImportedData[:,1]\n",
    "\n",
    "r = np.linspace(1,7,len(t))\n",
    "\n",
    "# these values need to be loaded from a Tikhonov fit \n",
    "P_init = PfromTikhonov\n",
    "delta_init = 1/alpha.^2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up model\n",
    "Vmax = np.amax(Vdata)*1.3\n",
    "K = kernel(t,r)\n",
    "\n",
    "L = regop(r,2) # this operator/functions needs to be written\n",
    "LtL = np.conjugate(L)*L\n",
    "\n",
    "with pm.Model() as gaussian_model: \n",
    "\n",
    "    ## Prior distributions as we had them before\n",
    "    k = pm.Gamma('k',alpha=1,beta=0.05)\n",
    "\n",
    "    sigma = pm.Gamma('sigma', alpha=1, beta=0.1)\n",
    "\n",
    "    lambd = pm.Beta('lambda', alpha=1.3, beta=2.0)\n",
    "\n",
    "    BoundedNormal = pm.Bound(pm.Normal,lower=0.0)\n",
    "    V0 = BoundedNormal('V0', mu=1.0, sigma=0.2)\n",
    "\n",
    "    # new prior for delta\n",
    "    # this currently does not take into account P\n",
    "    delta = pm.Gamma('delta',alpha = 0.01, beta = 1e-6)\n",
    "\n",
    "    # some math operations\n",
    "    tau = 1/sigma.^2\n",
    "\n",
    "    tauKtK = tau*(np.conjugate(K)*K)\n",
    "\n",
    "    S = K*P\n",
    "    tauKtS = tau*np.conjugate(K)*S\n",
    "\n",
    "    ## generate a P\n",
    "    P_init = randP(delta_init,tauKtK,tauKtS,LtL,nt)\n",
    "\n",
    "    ### This needs to be the manual sampler/step -----------------------------------\n",
    "    invSigma = tauKtK + delta*LtL\n",
    "    try\n",
    "    #'lower' syntax is faster for sparse matrices. Also matches convention in Bardsley paper.\n",
    "        C_L = chol(inv(invSigma),'lower')\n",
    "    catch\n",
    "        C_L = sqrtm(inv(invSigma))\n",
    "    end\n",
    "    v = randn(nt,1)\n",
    "    w = C_L.'\\v\n",
    "    P = fnnls(invSigma,tauKtS+w)\n",
    "\n",
    "    ##### ----------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "    ## Calculate signal\n",
    "    Vmodel = V0*(1-lambd+lambd*S)*np.exp(-k*np.abs(t)))\n",
    "\n",
    "    ## Likelihood\n",
    "    V = pm.Normal('V', mu=Vmodel, sigma=sigma, observed=Vdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sampling\n",
    "with gaussian_model: \n",
    "    trace = pm.sample(draws=draws,tune=tune,chains=chains,cores=cores)\n",
    "\n",
    "\n",
    "df_ = pm.trace_to_dataframe(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}